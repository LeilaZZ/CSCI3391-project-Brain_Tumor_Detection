{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4mbsnRLVCkAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/zzc2/"
      ],
      "metadata": {
        "id": "gyRGgwnlCks2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ks9jZa_2Aus",
        "outputId": "ca05df1f-e57d-4acb-ad61-6eb52349d219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'detr'...\n",
            "remote: Enumerating objects: 265, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 265 (delta 0), reused 1 (delta 0), pack-reused 264\u001b[K\n",
            "Receiving objects: 100% (265/265), 12.88 MiB | 20.19 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/detr.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c pytorch pytorch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC5jPVbP2PgL",
        "outputId": "5b0a4ca7-4fa5-4679-c812-4565ec7e1f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install cython scipy\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhgp2cH-5kgr",
        "outputId": "c966cd54-7b58-4996-a717-933c47a13018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-r5jq464d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-r5jq464d\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (67.7.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.0.10)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=375614 sha256=039dd505381ee5cf79a299e7e2659cc7560d4612bdedd60b9cbd0573ea717d57\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-edi74h8k/wheels/39/61/b4/480fbddb4d3d6bc34083e7397bc6f5d1381f79acc68e9f3511\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.7\n",
            "    Uninstalling pycocotools-2.0.7:\n",
            "      Successfully uninstalled pycocotools-2.0.7\n",
            "Successfully installed pycocotools-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def yolo_to_coco(yolo_labels_path, coco_output_path):\n",
        "    coco_data = {\"images\": [], \"annotations\": [], \"categories\": [{\"id\": 1, \"name\": \"object\"}]}\n",
        "    image_id = 0\n",
        "    annotation_id = 0\n",
        "\n",
        "    # Read YOLO label files\n",
        "    with open(yolo_labels_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            # Parse label line (assuming \"<class_id> <x_center> <y_center> <width> <height>\")\n",
        "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "\n",
        "            # Convert YOLO bounding box to COCO format\n",
        "            x_min = (x_center - width / 2)\n",
        "            y_min = (y_center - height / 2)\n",
        "\n",
        "            # Add image entry to COCO data\n",
        "            coco_data[\"images\"].append({\"id\": image_id, \"file_name\": \"image.jpg\", \"width\": 640, \"height\": 480})\n",
        "\n",
        "            # Add annotation entry to COCO data\n",
        "            coco_data[\"annotations\"].append({\n",
        "                \"id\": annotation_id,\n",
        "                \"image_id\": image_id,\n",
        "                \"category_id\": 1,  # Assuming only one category\n",
        "                \"bbox\": [x_min, y_min, width, height],\n",
        "                \"area\": width * height,\n",
        "                \"iscrowd\": 0  # Assuming not a crowd annotation\n",
        "            })\n",
        "\n",
        "            # Increment IDs\n",
        "            image_id += 1\n",
        "            annotation_id += 1\n",
        "\n",
        "    # Write COCO data to JSON file\n",
        "    with open(coco_output_path, \"w\") as f:\n",
        "        json.dump(coco_data, f)\n",
        "\n",
        "# Example usage\n",
        "yolo_labels_path = \"content/drive/MyDrive/zzc2/dataset (1)/labels (1)/\"\n",
        "coco_output_path = \"path/to/coco_annotations.json\"\n",
        "yolo_to_coco(yolo_labels_path, coco_output_path)\n"
      ],
      "metadata": {
        "id": "UzNchNi5AsxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DetrForObjectDetection\n",
        "from transformers import DetrForObjectDetection, DetrForObjectDetectionConfig\n",
        "from datasets import CocoDetection, CocoDetectionSplit\n",
        "\n",
        "# Define your training parameters\n",
        "batch_size = 2\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Load the COCO dataset\n",
        "train_dataset = CocoDetectionSplit(root=\"path/to/coco\", annFile=\"path/to/train_annotation.json\")\n",
        "val_dataset = CocoDetectionSplit(root=\"path/to/coco\", annFile=\"path/to/val_annotation.json\")\n",
        "\n",
        "# Define data transforms\n",
        "transform = T.Compose([\n",
        "    T.Resize((800, 800)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Apply transforms to the datasets\n",
        "train_dataset.transform = transform\n",
        "val_dataset.transform = transform\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the DETR model and optimizer\n",
        "config = DetrForObjectDetectionConfig.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", config=config)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define the loss function (DETR uses a custom loss combining classification and bounding box regression)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, targets=targets)\n",
        "        loss = loss_fn(outputs.logits, outputs.logits_bbox)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print average loss for this epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "    # Validation loop (optional)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        for images, targets in val_loader:\n",
        "            outputs = model(images, targets=targets)\n",
        "            loss = loss_fn(outputs.logits, outputs.logits_bbox)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    # Print validation loss\n",
        "    print(f\"Validation Loss: {val_loss / len(val_loader)}\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(\"path/to/save/trained_model\")\n"
      ],
      "metadata": {
        "id": "tBv_X8KX-bnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=8 --use_env main.py --coco_path /path/to/coco"
      ],
      "metadata": {
        "id": "MwTVNehF8KEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --batch_size 2 --no_aux_loss --eval --resume https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth --coco_path /path/to/coco"
      ],
      "metadata": {
        "id": "I22ddiR48LRC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
